{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp DatacompyReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DatacompyReport\n",
    "\n",
    "> Added reporting functionality for `Datacompy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import datacompy\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas\n",
    "from fastcore.utils import *\n",
    "\n",
    "class DatacompyReport():\n",
    "    \"\"\"A class to modify the output of a datacompy instance and add reporting functionality\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 compare_instance): # a datacompy.core.Compare instance\n",
    "        self.compare_instance = compare_instance\n",
    "        self.column_summary = pandas.DataFrame(\n",
    "            {\n",
    "                'Quantity': [\n",
    "\n",
    "                    f\"Total Columns {self.compare_instance.df1_name}\",\n",
    "                    f\"Total Columns {self.compare_instance.df2_name}\",\n",
    "                    f\"Columns in Common\",\n",
    "                    f\"Columns in {self.compare_instance.df1_name} but not in {self.compare_instance.df2_name}\",\n",
    "                    f\"Columns in {self.compare_instance.df2_name} but not in {self.compare_instance.df1_name}\",\n",
    "                    \"Number of columns compared with some values unequal\",\n",
    "                    \"Number of columns compared with all values equal\",\n",
    "                    \"Total number of values which compare unequal\"\n",
    "\n",
    "\n",
    "                ],\n",
    "                'Value': [\n",
    "\n",
    "                    self.compare_instance.df1.shape[1],\n",
    "                    self.compare_instance.df2.shape[1],\n",
    "                    len(self.compare_instance.intersect_columns()),\n",
    "                    len(self.compare_instance.df1_unq_columns()), \n",
    "                    len(self.compare_instance.df2_unq_columns()),\n",
    "                    len([col for col in self.compare_instance.column_stats if col[\"unequal_cnt\"] > 0]),\n",
    "                    len([col for col in self.compare_instance.column_stats if col[\"unequal_cnt\"] == 0]),\n",
    "                    sum([col[\"unequal_cnt\"] for col in self.compare_instance.column_stats])\n",
    "                ]\n",
    "\n",
    "            }\n",
    "        ).set_index('Quantity')\n",
    "        \n",
    "        self.row_summary = pandas.DataFrame(\n",
    "            {\n",
    "                'Quantity': [\n",
    "                    \"Matched On\", \n",
    "                    \"Any duplicates on Match Values\", \n",
    "                    \"Absolute/Relative Tolerance\",\n",
    "                    f\"Total Rows {self.compare_instance.df1_name}\",\n",
    "                    f\"Total Rows {self.compare_instance.df2_name}\",\n",
    "                    \"Rows with Key Matches but Non-Key Differences\",\n",
    "                    f\"Rows Only in {self.compare_instance.df1_name}\",\n",
    "                    f\"Rows Only in {self.compare_instance.df2_name}\",\n",
    "                    \"Number of rows with some compared columns unequal\",\n",
    "                    \"Number of rows with all compared columns equal\"\n",
    "                ],\n",
    "                'Value': [\n",
    "                    self.compare_instance.join_columns, \n",
    "                    self.compare_instance._any_dupes, \n",
    "                    f\"{self.compare_instance.abs_tol}, {self.compare_instance.rel_tol}\",\n",
    "                    self.compare_instance.df1.shape[0],\n",
    "                    self.compare_instance.df2.shape[0],\n",
    "                    self.compare_instance.intersect_rows.shape[0],\n",
    "                    self.compare_instance.df1_unq_rows.shape[0],\n",
    "                    self.compare_instance.df2_unq_rows.shape[0],\n",
    "                    self.compare_instance.intersect_rows.shape[0] - self.compare_instance.count_matching_rows(),\n",
    "                    self.compare_instance.count_matching_rows()\n",
    "\n",
    "                ]\n",
    "\n",
    "            }\n",
    "        ).set_index('Quantity')\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\" datacompy_report instance:\\n Comparing: {self.compare_instance.df1_name} and {self.compare_instance.df2_name}\"\n",
    "        \n",
    "    __repr__ = __str__\n",
    "    \n",
    "    def _autosize_excel_columns_df(self, worksheet, df, offset=0):\n",
    "        \"\"\"Helper utility to appropriately widen column of Excel Spreadsheet\"\"\"\n",
    "\n",
    "        for idx, col in enumerate(df):\n",
    "            series = df[col]\n",
    "            max_len = max((series.astype(str).map(len).max(),len(str(series.name)))) + 1\n",
    "            worksheet.set_column(idx+offset, idx+offset, max_len)  \n",
    "                   \n",
    "    def _autosize_excel_columns(self, worksheet, df):\n",
    "        \"\"\"Helper ulitlity to apply across all columns and the index\"\"\"\n",
    "\n",
    "        self._autosize_excel_columns_df(worksheet, df.index.to_frame())\n",
    "        self._autosize_excel_columns_df(worksheet, df, offset=df.index.nlevels)\n",
    "\n",
    "    def _make_worksheet(self, writer, df, sheet_name):\n",
    "        \"\"\"Helper utility to add DataFrame as worksheet to excel notebook\"\"\"\n",
    "\n",
    "        if df.shape[0] > 1048576:\n",
    "            print('Note: Excel workbooks have a limit of 1048576 rows, 16384 columns, and column widths of 255.')\n",
    "            return None\n",
    "    \n",
    "        if df.shape[0] > 0:\n",
    "            df.to_excel(\n",
    "                writer, \n",
    "                sheet_name=sheet_name, \n",
    "                freeze_panes=(df.columns.nlevels, df.index.nlevels)\n",
    "            )\n",
    "            self._autosize_excel_columns(writer.sheets[sheet_name], df)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def prepare_compare_results(self:DatacompyReport) -> 'pandas.DataFrame':\n",
    "    \n",
    "    \"\"\"Reformats the Datacompy output to display all column differences found\n",
    "    for matches between the two DataFrames based on the keys compare.join_columns\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    compare : instance of datacompy.Compare class\n",
    "        An initialized datacompy.Compare() instance\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing all records found in both tables where there\n",
    "        was at least one difference found in a non-key column. Further, columns\n",
    "        where the two DataFrames match are blanked out to make visual inspection\n",
    "        of the differences stand out.\n",
    "    \"\"\"\n",
    "\n",
    "    def _blank_matches(row: 'pd.DataFrame', col: str) -> 'pandas.DataFrame':\n",
    "        \"\"\"To reduce visual clutter, blank out entries where dataframes match.\n",
    "            Meant to be applied across the rows of a difference_intersection DataFrame\n",
    "            for a specific column at a time. This is just a helper function for .apply\n",
    "            and I cannot think of a great way to do this. (TODO)\n",
    "\n",
    "        \"\"\"\n",
    "        if row[f'{col}_match']:\n",
    "            row[f'{col}_df1'] = ''\n",
    "            row[f'{col}_df2'] = ''\n",
    "            row[f'{col}_match'] = ''\n",
    "        return row\n",
    "\n",
    "    # Get the max number of comparisons made\n",
    "    match_columns = self.compare_instance.intersect_rows.columns.str.contains('_match$', regex=True)\n",
    "    len_cols_compare = match_columns.sum()\n",
    "\n",
    "    # Find the number of matches for each row\n",
    "    remove_rows_all_equal = self.compare_instance.intersect_rows.iloc[:,match_columns].sum(axis=1)\n",
    "\n",
    "    # Remove rows were all compared columns were equal \n",
    "    remove_rows_all_equal = remove_rows_all_equal[(remove_rows_all_equal != len_cols_compare) == True]\n",
    "\n",
    "    # Display the intersection only where at least one discrepancy is detected\n",
    "    difference_intersection = self.compare_instance.intersect_rows.loc[remove_rows_all_equal.index]\n",
    "    compare_cols = [item for item in self.compare_instance.intersect_columns() if item not in self.compare_instance.join_columns]\n",
    "\n",
    "    # Get only the desired columns and in the desired order\n",
    "    intersect_columns = []\n",
    "    for item in sorted(compare_cols):\n",
    "        for suf in ['_df1', '_df2', '_match']:\n",
    "            intersect_columns.append(item + suf) \n",
    "    difference_intersection = difference_intersection[intersect_columns + self.compare_instance.join_columns]\n",
    "\n",
    "    # Blank values where DataFrames match\n",
    "    for col in compare_cols:\n",
    "        difference_intersection = difference_intersection.apply(lambda row: _blank_matches(row, col), axis = 1)\n",
    "\n",
    "    cols_to_delete = difference_intersection.columns[difference_intersection.columns.str.contains('_match$', regex=True)]\n",
    "    difference_intersection.drop(columns = cols_to_delete, inplace=True)\n",
    "    difference_intersection.set_index(self.compare_instance.join_columns, inplace=True)\n",
    "\n",
    "    return difference_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def create_excel_report(self:DatacompyReport, \n",
    "                        write_file: str) -> None: # file where you want the Excel file to be created\n",
    "    \n",
    "    \"\"\"Create Excel workbook with nicely formatted output comparing two DataFrames\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    compare : instance of datacompy.core.Compare class\n",
    "        An initialized datacompy.core.Compare() instance\n",
    "\n",
    "    write_file : path to where the Excel Workbook should be created\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Excel workbook written at write_file location\n",
    "    \"\"\"\n",
    "\n",
    "    column_stats_summary = pandas.DataFrame(self.compare_instance.column_stats).set_index('column')\n",
    "    matched_compare = self.prepare_compare_results()\n",
    "\n",
    "    try:\n",
    "        with pandas.ExcelWriter(write_file, engine='xlsxwriter') as writer: \n",
    "\n",
    "            self._make_worksheet(writer=writer, df=self.row_summary, sheet_name='Row Summary')\n",
    "            self._make_worksheet(writer=writer, df=self.column_summary, sheet_name='Column Summary')\n",
    "            self._make_worksheet(writer=writer, df=column_stats_summary, sheet_name='Column Stats')\n",
    "            self._make_worksheet(\n",
    "                writer=writer, \n",
    "                df=self.compare_instance.df1_unq_rows.set_index(self.compare_instance.join_columns), \n",
    "                sheet_name=f'{self.compare_instance.df1_name} Only Observations'\n",
    "            )\n",
    "            self._make_worksheet(\n",
    "                writer=writer, \n",
    "                df=self.compare_instance.df2_unq_rows.set_index(self.compare_instance.join_columns), \n",
    "                sheet_name=f'{self.compare_instance.df2_name} Only Observations'\n",
    "            )\n",
    "            self._make_worksheet(writer=writer, df=matched_compare, sheet_name='Matched Differences')\n",
    "\n",
    "        print(\"Excel Workbook has been created\")\n",
    "\n",
    "    except OSError as err:\n",
    "        print(\"OS error:\", err)\n",
    "    except ValueError as err:\n",
    "        print(f\"Value error: {err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"Unexpected {err}, {type(err)}\")\n",
    "        raise\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = \"\"\"id,col1_string,col2_string,col3_int,col4_float,col5_string\n",
    "010,g1,g1-duck,1,1.0,r1\n",
    "110,g1,g1-dog,2,2.1,r1\n",
    "210,g2,g2-duck,3,3.2,r2\n",
    "310,g2,g2-dog,4,4.3,r2\n",
    "410,g1,g1-goat,5,5.4,r1\n",
    "510,,g1-dog,6,6.5,r1\n",
    "610,g2,g2-dog,7,7.6,r2\n",
    "710,g2,g2-duck,8,8.7,r2\n",
    "810,g1,g1-dog,9,9.8,r1\n",
    "811,g1,g1-duck,10,10.9,r1\n",
    "812,g1,g1-duck,11,11.0,r1\"\"\"\n",
    "\n",
    "data2 = \"\"\"id,col1_string,col2_string,col3_int,col4_float,col6_string\n",
    "010,g1,g1-duck,1,1.0,z1\n",
    "110,g2,g2-duck,2,2.1,z2\n",
    "210,g2,g2-duck,4,3.3,z2\n",
    "310,g1,g1-dog,3,4.5,z1\n",
    "410,g1,g1-dog,5,5.9,z1\n",
    "510,g1,g1-dog,6,6.5,z2\n",
    "610,g2,g2-goat,7,,z2\n",
    "710,g2,g2-duck,8,8.7,z1\n",
    "810,g1,g1-dog,9,9.8,z1\n",
    "911,g2,g2-dog,10,10.91,z2\n",
    "912,g2,g2-dog,11,11.01,z2\n",
    "922,g1,g1-duck,12,11.1,z2\n",
    "\"\"\"\n",
    "\n",
    "df1 = pandas.read_csv(StringIO(data1))\n",
    "df2 = pandas.read_csv(StringIO(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Datacompy Compare Instance to Compare `df1` and `df2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = datacompy.Compare(\n",
    "    df1,\n",
    "    df2,\n",
    "    join_columns=['id', 'col1_string'],  # You can also specify a list of columns\n",
    "    abs_tol=0,                           # Optional, defaults to 0\n",
    "    rel_tol=0,                           # Optional, defaults to 0\n",
    "    df1_name='Base',                     # Optional, defaults to 'df1'\n",
    "    df2_name='Compare'                   # Optional, defaults to 'df2'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a New DataCompyReport Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " datacompy_report instance:\n",
       " Comparing: Base and Compare"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = DatacompyReport(compare)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.compare_instance` attribute is the `datacompy.core.Compare` object. `datacompy.core.Compare` attributes can be accessed directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare.abs_tol\n",
      "compare.all_columns_match\n",
      "compare.all_mismatch\n",
      "compare.all_rows_overlap\n",
      "compare.cast_column_names_lower\n",
      "compare.column_stats\n",
      "compare.count_matching_rows\n",
      "compare.df1\n",
      "compare.df1_name\n",
      "compare.df1_unq_columns\n",
      "compare.df1_unq_rows\n",
      "compare.df2\n",
      "compare.df2_name\n",
      "compare.df2_unq_columns\n",
      "compare.df2_unq_rows\n",
      "compare.ignore_case\n",
      "compare.ignore_spaces\n",
      "compare.intersect_columns\n",
      "compare.intersect_rows\n",
      "compare.intersect_rows_match\n",
      "compare.join_columns\n",
      "compare.matches\n",
      "compare.on_index\n",
      "compare.rel_tol\n",
      "compare.report\n",
      "compare.sample_mismatch\n",
      "compare.subset\n"
     ]
    }
   ],
   "source": [
    "for item in dir(compare):\n",
    "    if item[0] != '_':\n",
    "        print(f'compare.{item}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Modified Matched Differences Report\n",
    "\n",
    "`Datacompy` provides most of the methods, attributes needed to create a very useful comparison report. For some  particular use cases it can be necessary to represent the data where matches on *key* columns are found but at least one difference exists (value and/or type) in a column they both share. Further, there is no added value reporting values in columns where the two DataFrames match for this use case so matching values are blanked out.\n",
    "\n",
    "To extract this table:\n",
    "`report.prepare_compare_results()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>col2_string_df1</th>\n",
       "      <th>col2_string_df2</th>\n",
       "      <th>col3_int_df1</th>\n",
       "      <th>col3_int_df2</th>\n",
       "      <th>col4_float_df1</th>\n",
       "      <th>col4_float_df2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>col1_string</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <th>g2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <th>g1</th>\n",
       "      <td>g1-goat</td>\n",
       "      <td>g1-dog</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <th>g2</th>\n",
       "      <td>g2-dog</td>\n",
       "      <td>g2-goat</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                col2_string_df1 col2_string_df2 col3_int_df1 col3_int_df2  \\\n",
       "id  col1_string                                                             \n",
       "210 g2                                                   3.0          4.0   \n",
       "410 g1                  g1-goat          g1-dog                             \n",
       "610 g2                   g2-dog         g2-goat                             \n",
       "\n",
       "                 col4_float_df1  col4_float_df2  \n",
       "id  col1_string                                  \n",
       "210 g2                      3.2             3.3  \n",
       "410 g1                      5.4             5.9  \n",
       "610 g2                      7.6             NaN  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.prepare_compare_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Excel Report\n",
    "\n",
    "To create an excel report, use `report.create_excel_report('comparison_report_test_data2.xlsx')`.\n",
    "\n",
    "The workbook will contain multiple sheets:\n",
    "\n",
    "+ **Row Summary** - comparison of DataFrame1 and DataFrame2 by row\n",
    "+ **Column Summary** - comparison of DataFrame1 and DataFrame2 by row\n",
    "+ **Columns Stats Summary** - comparison of column metadata for DataFrame1 and DataFrame2\n",
    "+ **DataFrame1 Observations Only** - all rows (by key, `self.compare_instance.join_columns`) found in DataFrame 1 but not DataFrame 2\n",
    "+ **DataFrame2 Observations Only** - all rows (by key, `self.compare_instance.join_columns`) found in DataFrame 2 but not DataFrame 1\n",
    "+ **Matched Differences** - all rows (by key, `self.compare_instance.join_columns`) found in both DataFrame1 and DataFrame2 having at least one difference in a non-key field. The Matched Differences DataFrame replaces all fields where the DataFrames match with blanks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel Workbook has been created\n"
     ]
    }
   ],
   "source": [
    "report.create_excel_report('comparison_report_test_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
